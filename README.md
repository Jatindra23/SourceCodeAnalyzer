# ğŸ” Source Code Analyzer

A web-based application that allows users to analyze and query source code from any public GitHub repository using natural language. Built using **LangChain**, **OpenAI**, **ChromaDB**, and **Flask**.

---

## ğŸš€ Features

- ğŸ”— Clone any public Python GitHub repository.
- ğŸ“„ Parse and split source code into manageable chunks.
- ğŸ§  Create vector embeddings using OpenAI.
- ğŸ—ƒï¸ Store and retrieve vectors using ChromaDB.
- ğŸ’¬ Ask natural language questions about the code and receive intelligent responses.

---

## ğŸ› ï¸ Tech Stack

- Python
- Flask
- LangChain
- OpenAI API
- ChromaDB
- GitPython
- python-dotenv

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                # Main Flask application
â”œâ”€â”€ store_index.py        # Script to process repo and store vectors
â”œâ”€â”€ src/
â”‚   â””â”€â”€ helper.py         # Helper functions (clone, load, split, embed)
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Web frontend (not included here)
â”œâ”€â”€ repo/                 # Cloned repositories
â”œâ”€â”€ db/                   # Persistent ChromaDB vector store
â”œâ”€â”€ .env                  # Environment file for API key
â””â”€â”€ README.md             # Project documentation
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/source-code-analyzer.git
cd source-code-analyzer
```

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # For Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Set your OpenAI API Key

Create a `.env` file in the root directory:

```
OPENAI_API_KEY=your_openai_api_key_here
```

---

## ğŸ’¡ How It Works

1. User inputs a GitHub repo URL via the web interface.
2. The repo is cloned locally using `repo_ingestion()`.
3. Python files are loaded and split into chunks with `load_repo()` and `text_splitter()`.
4. Text chunks are embedded via OpenAI's embedding model.
5. Embeddings are stored in ChromaDB (`store_index.py`).
6. Users can chat with the code using LangChain's `ConversationalRetrievalChain`.

---

## ğŸ§ª Running the Application

### Step 1: Run the vector store indexing script

```bash
python store_index.py
```

### Step 2: Launch the Flask app

```bash
python app.py
```

Navigate to `http://localhost:8080` in your browser.

---

## ğŸ“¬ Endpoints

- `/` â†’ Renders homepage with form
- `/chatbot` â†’ Accepts GitHub repo URL and ingests repo
- `/get` â†’ Accepts a message and returns model-generated answer

---

## ğŸ“Œ Example Use Case

- Enter: `https://github.com/entbappy/End-to-end-Medical-Chatbot-Generative-AI`
- Ask: *"What does the main function do?"* or *"Which model is being used for intent classification?"*

---

## ğŸ¤– Powered By

- [LangChain](https://www.langchain.com/)
- [OpenAI](https://openai.com/)
- [Chroma](https://www.trychroma.com/)

---

## ğŸ“„ License

MIT License. Feel free to fork, enhance, and use.